# <font color=#0099ff> **é€Ÿé€šæ¦‚å¿µ --> LLM æ–‡æœ¬å¤§æ¨¡å‹** </font>

> `@think3r` 2025-02-08 23:50:03
>
> - [å®‰å¾·çƒˆÂ·å¡å¸•è¥¿æœ€æ–°AIæ™®åŠè¯¾ï¼šæ·±å…¥æ¢ç´¢åƒChatGPTè¿™æ ·çš„å¤§è¯­è¨€æ¨¡å‹ Andrej Karpathy](https://www.bilibili.com/video/BV1WnNHeqEFK)
>   - ori : <https://www.youtube.com/watch?v=7xTGNNLPyMI>
> - [ğŸ· FineWeb: decanting the web for the finest text data at scale](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)

## <font color=#009A000> 0x00 ç®€ä»‹ </font>

<https://drive.google.com/file/d/1EZh5hNDzxMMy05uLhVryk061QYQGTxiN/view>

![llvmIntro](./image/LLMIntro-2024-07-22-1743.svg)

## <font color=#009A000> 0x01 çŸ¥è¯†ç‚¹ </font>

1. é¢„è®­ç»ƒ pre-trainning
   - [huggingFace-FineWeb æ•°æ®é›†](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1) --> è¿‡æ»¤åçš„æœ€ç»ˆæ–‡æœ¬æ•°æ® `44TB`
     - CommonCrawl çš„ç½‘ç»œçˆ¬è™«
     - url-filtering : <https://dsi.ut-capitole.fr/blacklists/>
     - text-extraction : å»é™¤ html æ ‡è®°
     - lang-filtering : ä¿ç•™ 85% ä»¥ä¸Šè‹±æ–‡çš„ç½‘é¡µ
     - ... é‡å¤ä¿¡æ¯åˆ é™¤
     - PII remove : personally identifiable information remove ä¸ªäººä¿¡æ¯ç§»é™¤
     - æœ€ç»ˆå¤„ç†ç»“æœ : <https://huggingface.co/datasets/HuggingFaceFW/fineweb?row=0> -> Dataset Preview éƒ¨åˆ†
2. tokenization :
   - Converts text <---> sequences of symbols (/tokens) å°½å¯èƒ½çš„å‹ç¼©æ–‡æœ¬æ•°æ®é‡
     - why ?
   - <https://tiktokenizer.vercel.app/>
3. neural network training :
   1. çª—å£ä¸Šä¸‹æ–‡æ•°é‡ maximum-context-length
   2. LLM Visualization : <https://bbycroft.net/llm>
   3. gpt :
      - è®ºæ–‡ : attention is all you need
      - TODO: è®ºæ–‡é˜…è¯»å·¥å…·...
      - GPT2 :
        - <https://github.com/openai/gpt-2.git>
        - è®ºæ–‡ : <https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf>
          - [è®ºæ–‡é˜…è¯»ï¼šLanguage Models are Unsupervised Multitask Learners](https://zhuanlan.zhihu.com/p/711058430)
        - å¤ç°é¡¹ç›® : `LLM.c` --> <https://github.com/karpathy/LLM.c/discussions/677>
      - llama-3 :
        - è®ºæ–‡ : [The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783)
   4. ç½‘ç»œç»“æ„ : `model.py`
4. (åŸºç¡€)æ¨¡å‹ :
   - åˆ†ç±»
     1. base-model åŸºç¡€æ¨¡å‹
     2. instruct-model æŒ‡ä»¤æ¨¡å‹
   - æœ¬è´¨ä¸Šæ˜¯å¯¹è®­ç»ƒæ•°æ®(äº’è”ç½‘æ•°æ®)çš„ä¸€ç§æœ‰æŸå‹ç¼©
   - è®­ç»ƒæ•°æ®æ˜¯è½åä¸çœŸå®ä¸–ç•Œçš„äº’è”ç½‘çš„, è€Œæ¨¡å‹çš„å›ç­”åªæ˜¯å¯¹å†å²äº’è”ç½‘æ•°æ®çš„æ¨¡ç³Šå›å¿†, å› æ­¤å…¶å›ç­”ä¸å¯ä¿¡
   - å½“ä½ å¤åˆ¶ wikipedia çš„å†…å®¹æ¥æé—®æ—¶, æ¨¡å‹å¯èƒ½è¾“å‡ºå’Œ wiki å®Œå…¨ä¸€è‡´çš„å›ç­”
     - ååˆ regurgitation : ç›´æ¥å¼•ç”¨å·²è®­ç»ƒè¿‡çš„æ•°æ®
     - åŸå›  : Wikipedia è¢«è®¤ä¸ºæ˜¯é«˜è´¨é‡æ•°æ®, å¯èƒ½æœ‰è¾ƒé«˜çš„è®­ç»ƒä¼˜å…ˆçº§(è®­ç»ƒ/çœ‹è¿‡ 10 æ¬¡, ä»¥è‡³äºæ¨¡å‹åƒäººä¸€æ ·å®Œå…¨è®°ä½äº†)
   - æç¤º prompt
     - in-context learning ä¸Šä¸‹æ–‡å­¦ä¹  --> è§£å†³æœªçŸ¥é—®é¢˜çš„ä¸€éƒ¨åˆ†èƒ½åŠ›
     - (åŸºç¡€æ¨¡å‹)çš„æç¤ºè¯ prompt çš„æ’°å†™/ä¼˜åŒ–
5. post-trainning åè®­ç»ƒ : supervised fine-tuning ç›‘ç£å¾®è°ƒ (`SFT`) --> ä¸ªæ€§çš„å‡ºç°
   - human labelers (äººå·¥æ ‡æ³¨è€…) æ‰‹åŠ¨å›ç­”é—®é¢˜, ç”¨äºæ¨¡å‹åè®­ç»ƒ
     - æ•°æ®é›†å¾ˆå°, å› æ­¤è®­ç»ƒæ—¶é—´ä¼šå¾ˆçŸ­
   - tokenization çš„ encoding : è§ä¸Šå›¾çš„ `Conversation Protocol / Format`
     - NOTE: `<|im_start|>` æ˜¯ä¸€ä¸ªæ ‡ç­¾, åŸºç¡€æ¨¡å‹å¹¶ä¸åŒ…å«, å…¶æ˜¯æ–°å¢çš„
     - è®ºæ–‡ : [Training language models to fol instructions with human feedback](https://arxiv.org/pdf/2203.02155)
     - äººå·¥æ ‡æ³¨å›ç­”çš„æŒ‡å¯¼æ–‡æ¡£é€šå¸¸æœ‰å‡ åé¡µä¹‹å¤š
     - å¼€æºçš„æ ‡æ³¨é›† : [OpenAssistant/oasst2](https://huggingface.co/datasets/OpenAssistant/oasst2)
     - ç°åœ¨å¤šä½¿ç”¨ LLM ç›´æ¥ç”Ÿæˆç­”æ¡ˆ, ç„¶åç¼–è¾‘å®ƒ, è€Œä¸æ˜¯ä»å¤´æ‰‹åŠ¨ç¼–å†™, e.g. : [ultraChat](https://github.com/thunlp/UltraChat)
       - SFT æ•°æ®é›† ?
       - æ¶µç›–çš„æ–¹é¢ : <https://atlas.nomic.ai/map/0ce65783-c3a9-40b5-895d-384933f50081/a7b46301-022f-45d8-bbf4-98107eabdbac>
       - æŸäº›ç‰¹å®šçš„æŠ€æœ¯/é¢†åŸŸéœ€è¦å¯¹åº”ä¸“å®¶çš„å‚ä¸æ ‡æ³¨ç¡®è®¤
   - LLM psyhology å¿ƒç†å­¦
     - Hallucinations å¹»è§‰ : å®Œå…¨è™šæ„ä¿¡æ¯
       - æ¶ˆé™¤æ–¹æ³• :
         1. > Use model interrogation to discover model's knowledge, and programmatically augment its training dataset with knowledge-based refusals in cases where the model doesn't know
            - åˆ©ç”¨æ¨¡å‹è¯¢é—®æ¥å‘æ˜æ¨¡å‹çš„çŸ¥è¯†ï¼Œå¹¶åœ¨æ¨¡å‹ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç¼–ç¨‹æ–¹å¼ç”¨åŸºäºçŸ¥è¯†çš„æ‹’ç»æ¥æ‰©å……å…¶è®­ç»ƒæ•°æ®é›†ã€‚
            - (ç”¨æ–°çš„çŸ¥è¯†è¯¢é—®å¥½çš„æ¨¡å‹, å¾—å‡ºç­”æ¡ˆ(æ¨ç†), ç„¶åå°†å…¶åŠ å…¥è®­ç»ƒé›†) : ç½‘ç»œä¸­æŸä¸ªç¥ç»å…ƒå€¼å¾ˆé«˜æ—¶, è®©æ¨¡å‹è¾“å‡ºä¸çŸ¥é“(åŠ å¼ºè¿™ç§èƒ½åŠ›çš„è®­ç»ƒ)
         2. > Allow the model to search!
            - `<SEARCH_START>` å¼•å…¥çš„æ–° token, æœç´¢å¼•æ“æœç´¢, çˆ¬è™«, è¿›å…¥ä¸Šä¸‹æ–‡çª—å£(éšå½¢), åç»­çš„å›ç­”å°±è¿›å…¥äº†ä¸‹ä¸€ä¸ª context-window (å·¥ä½œå†…å­˜), è€Œè¯¥çŠ¶æ€ä¸­åŒ…å«äº†æœç´¢çš„ä¿¡æ¯
       > - Knowledge in the parameters == Vague recollection (e.g. of something you read 1 month ago) (å‚æ•°ä¸­çš„çŸ¥è¯†==æ¨¡ç³Šçš„å›å¿†ï¼ˆä¾‹å¦‚1ä¸ªæœˆå‰è¯»è¿‡çš„ä¸œè¥¿ï¼‰)
       > - Knowledge in the tokens of the   context window == Working memory  (ä¸Šä¸‹æ–‡çª—å£ç¬¦å·ä¸­çš„çŸ¥è¯†==å·¥ä½œè®°å¿†)
     - æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥ Knowledge of self
     - Models need tokens to think
       - æ¨¡å‹ä¸‹ä¸€ä¸ª tokens çš„ç”Ÿæˆä¸­è®¡ç®—é‡æ˜¯æœ‰é™çš„, ä¸å¯èƒ½ä¸€ä¸‹å­ç®—å‡ºå¤æ‚çš„ç»“æœ
       - å¦‚æœå¯ä»¥, è®©æ¨¡å‹ä½¿ç”¨å·¥å…·(code), è€Œä¸æ˜¯è®©æ¨¡å‹å°†å…¶å…¨éƒ¨å†…å®¹éƒ½å­˜å‚¨åœ¨ memory ä¸­
     - æ¨¡å‹ä¸æ“…é•¿è®¡æ•° : æ•°æŸä¸ªå­—ç¬¦çš„ä¸ªæ•°
     - Models are not good with spelling --> tokenization ç‚¹å‰¯ä½œç”¨, æ¨¡å‹çœ‹åˆ°çš„å¹¶ä¸æ˜¯å•è¯
       - tokenization çš„æ ¹æºæ˜¯ä¸ºäº†å‡å°‘è®¡ç®—é‡, ç›´æ¥è¾“å…¥å­—ç¬¦å°†ä¼šæ˜¯å¾ˆå¤§çš„è®¡ç®—é‡
         - ä¸­æ–‡åœ¨è¿™æ–¹é¢æ˜¯è¿˜ä¸æ˜¯ä¼šæ›´å¥½ ?
     - Bunch of other small random stuff
6. reinforcement-learning å¼ºåŒ–å­¦ä¹ (`RL` ä¾æ—§å±äº post-training çš„èŒƒç•´)
   - why ? --> ç±»ä¼¼äºäººçš„ä¸Šå­¦ ?
   - å°†é—®é¢˜å¤šæ¬¡è¯¢é—®æ¨¡å‹, å¾—åˆ°å…¶ä¸­æ­£ç¡®çš„, å°†å…¶å¡å…¥ä½œä¸ºæœªæ¥çš„è®­ç»ƒé›†ä¸­è¿›è¡Œå¼ºåŒ–è®­ç»ƒ.
   - æ–°å‡ºç°çš„é˜¶æ®µ, è¿˜ä¸æ˜¯å¾ˆæˆç†Ÿ
     - openAi å¹¶æœªå¼€æºå…¶æ–¹æ¡ˆ
     - deepseek çš„ R1 å¼ºåŒ–å­¦ä¹ è®ºæ–‡åŠå…¶å¼€æºçš„é‡è¦æ€§ --> é‡æ–°æ¿€å‘å…¬ä¼—å¯¹ä½¿ç”¨ RL è®­ç»ƒ LLM çš„å…´è¶£
       - è®ºæ–‡ : [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)
       - TODO: [è®ºæ–‡è§£è¯»DeepSeek-R1](https://zhuanlan.zhihu.com/p/19650946134)
       - thinking-model : æ€è€ƒæ¨¡å‹ FIXME:
         - **gpt-4O æ˜¯ SFT æ¨¡å‹, åŸºæœ¬æ²¡æœ‰è¿›è¡Œ RL è®­ç»ƒ(åšäº† RLHF)**
         - O1 çš„ç³»åˆ—æ¨¡å‹æ‰æ˜¯æ€è€ƒæ¨¡å‹(ç”¨äº† RL è®­ç»ƒ)
   - ä¸å¯éªŒè¯é¢†åŸŸä¸­çš„å¼ºåŒ–å­¦ä¹ é—®é¢˜. E.g. : å¹½é»˜æ„Ÿ, è¯»æ‘˜è¦, è¯—æ­Œåˆ›ä½œ, åˆ›æ„å†™ä½œ
     - è®ºæ–‡ `RLHF` (Reinforcement Learning from Human Feedback) --> [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593)
       - è®­ç»ƒå¦ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹å¥–åŠ±æ¨¡å‹, å¯¹è¢«è®­ç»ƒæ¨¡å‹çš„ç»“æœè¿›è¡Œè¯„åˆ†(æ’åº)
     - > We can run RL, in arbitrary domains! (even the unverifiable ones) This (empirically) improves the performance of the model, possibly due to the "discriminator - generator gap": In many cases, it is much easier to discriminate than to generate.  æˆ‘ä»¬å¯ä»¥åœ¨ä»»æ„åŸŸè¿è¡Œå¼ºåŒ–å­¦ä¹ ï¼ï¼ˆå³ä½¿æ˜¯æ— æ³•éªŒè¯çš„ï¼‰è¿™ï¼ˆç»éªŒä¸Šï¼‰æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå¯èƒ½æ˜¯ç”±äºâ€œåˆ¤åˆ«å™¨-ç”Ÿæˆå™¨å·®è·â€ï¼šåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œåˆ¤åˆ«æ¯”ç”Ÿæˆå®¹æ˜“å¾—å¤šã€‚
     - RLHF ç¼ºç‚¹ docnside :
       - > We are doing RL with respect to a lossy simulation of humans. It might be misleading!
       - > RL discovers ways to "game" the model. It discovers "adversarial examples" of the reward model.
         - å‰æœŸæ•ˆæœå¥½ ? åæœŸæœ‰å¾ˆå¤šå¯¹æŠ—æ€§æ ·æœ¬(adversarial examples), E.g. : the the the the è¢«è®¤ä¸ºæ˜¯æœ€å¥½ç¬‘çš„ç¬‘è¯
         - ä¸€èˆ¬åªè¿è¡Œå‡ ç™¾æ¬¡, ç„¶åè¦å‰ªæ
     - NOTE: å°†å°çš„ä¸“ä¸šçš„æ¨¡å‹, ä»¥ RL çš„æ–¹å¼é«˜æ•ˆçš„å¡åˆ°å¤§çš„æ¨¡å‹ä¸­ ?
     - æ€»ç»“ : RLHF å¹¶ä¸å®Œå…¨ç­‰ä»·äº RL, RLHF ä¸èƒ½æ°¸è¿œè¿è¡Œ,ä½†æ˜¯ RL å¯ä»¥(å…¶æœ‰ä¸ªæ˜ç¡®çš„åˆ¤æ–­æ ‡å‡†)
7. future æœªæ¥çš„æ¼”åŒ– :
   - multimodal (not just text but audio, images, video, natural conversations)
   - `tasks` -> `agents` (long, coherent, error-correcting contexts)
     - å·¥å‚çš„è‡ªåŠ¨åŒ–ç‡ --> æ•°å­—ä¸–ç•Œä¸­äººå·¥çš„ç›‘ç£
   - pervasive, invisible
   - computer-using
   - test-time training(å®æ—¶å­¦ä¹ )?, etc
     - context-window èµ„æºçš„å®è´µ
   - [lmarena.ai](https://lmarena.ai/) : LLM æ’è¡Œæ¦œ(äººå·¥)
   - `LMStudio` æœ¬åœ°è¿è¡Œæ¨¡å‹
